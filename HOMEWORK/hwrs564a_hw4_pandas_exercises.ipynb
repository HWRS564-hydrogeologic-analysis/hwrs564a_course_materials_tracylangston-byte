{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 - Pandas exercises\n",
    "\n",
    "We open with some imports as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some helpful functions \n",
    "just use these as be and don't worry too much about about them for now, we will learn how they work soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same data manipulation to get USGS streamflow as\n",
    "# a pandas dataframe as before\n",
    "def create_usgs_url(site_no, begin_date, end_date):\n",
    "    return (\n",
    "        f'https://waterdata.usgs.gov/nwis/dv?'\n",
    "        f'cb_00060=on&format=rdb&referred_module=sw&'\n",
    "        f'site_no={site_no}&'\n",
    "        f'begin_date={begin_date}&'\n",
    "        f'end_date={end_date}'\n",
    "    )\n",
    "\n",
    "def open_usgs_data(site, begin_date, end_date):\n",
    "    url = create_usgs_url((site), begin_date, end_date)\n",
    "    response = urllib.request.urlopen(url)\n",
    "    df = pd.read_table(\n",
    "        response,\n",
    "        comment='#',\n",
    "        skipfooter=1,\n",
    "        sep='\\s+',\n",
    "        names=['agency', 'site', 'date', 'streamflow (ft^3/s)', 'quality_flag'],\n",
    "        index_col=2,\n",
    "        #parse_dates=True,\n",
    "        engine='python'\n",
    "    ).iloc[2:]\n",
    "\n",
    "    # Now convert the streamflow data to floats and\n",
    "    # the index to datetimes. When processing raw data\n",
    "    # it's common to have to do some extra postprocessing\n",
    "    df['streamflow (ft^3/s)'] = df['streamflow (ft^3/s)'].astype(np.float64)\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "def open_daymet_data(lat, lon, begin_date, end_date):\n",
    "    args = {'lat':  lat, 'lon': lon, 'format': 'csv',\n",
    "            'start': begin_date, 'end': end_date}\n",
    "    query = urllib.parse.urlencode(args)\n",
    "    url = f\"https://daymet.ornl.gov/single-pixel/api/data?{query}\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    df = pd.read_csv(response, header=6)\n",
    "    datestring = (df['year'].astype(str) + df['yday'].astype(str))\n",
    "    dates = pd.to_datetime(datestring, format='%Y%j')\n",
    "    df.index = pd.DatetimeIndex(dates)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additionally, setting some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = '09506000'\n",
    "begin_date = '1992-09-25'\n",
    "end_date = '2022-09-25'\n",
    "lat = 34.4483605\n",
    "lon = -111.7898705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now open up some datasets from the above commands, you are almost to your exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>yday</th>\n",
       "      <th>dayl (s)</th>\n",
       "      <th>prcp (mm/day)</th>\n",
       "      <th>srad (W/m^2)</th>\n",
       "      <th>swe (kg/m^2)</th>\n",
       "      <th>tmax (deg c)</th>\n",
       "      <th>tmin (deg c)</th>\n",
       "      <th>vp (Pa)</th>\n",
       "      <th>streamflow (ft^3/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-09-25</th>\n",
       "      <td>1992</td>\n",
       "      <td>269</td>\n",
       "      <td>42469.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>413.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.57</td>\n",
       "      <td>12.92</td>\n",
       "      <td>1489.09</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-09-26</th>\n",
       "      <td>1992</td>\n",
       "      <td>270</td>\n",
       "      <td>42337.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.03</td>\n",
       "      <td>12.61</td>\n",
       "      <td>1459.42</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-09-27</th>\n",
       "      <td>1992</td>\n",
       "      <td>271</td>\n",
       "      <td>42204.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>436.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.89</td>\n",
       "      <td>11.41</td>\n",
       "      <td>1348.48</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-09-28</th>\n",
       "      <td>1992</td>\n",
       "      <td>272</td>\n",
       "      <td>42072.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>421.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.44</td>\n",
       "      <td>12.82</td>\n",
       "      <td>1479.16</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-09-29</th>\n",
       "      <td>1992</td>\n",
       "      <td>273</td>\n",
       "      <td>41940.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.42</td>\n",
       "      <td>14.18</td>\n",
       "      <td>1616.07</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  yday  dayl (s)  prcp (mm/day)  srad (W/m^2)  swe (kg/m^2)  \\\n",
       "1992-09-25  1992   269  42469.79            0.0        413.81           0.0   \n",
       "1992-09-26  1992   270  42337.25            0.0        419.69           0.0   \n",
       "1992-09-27  1992   271  42204.86            0.0        436.54           0.0   \n",
       "1992-09-28  1992   272  42072.64            0.0        421.55           0.0   \n",
       "1992-09-29  1992   273  41940.63            0.0        380.67           0.0   \n",
       "\n",
       "            tmax (deg c)  tmin (deg c)  vp (Pa)  streamflow (ft^3/s)  \n",
       "1992-09-25         33.57         12.92  1489.09                129.0  \n",
       "1992-09-26         34.03         12.61  1459.42                121.0  \n",
       "1992-09-27         34.89         11.41  1348.48                122.0  \n",
       "1992-09-28         35.44         12.82  1479.16                127.0  \n",
       "1992-09-29         33.42         14.18  1616.07                120.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verde_df = open_daymet_data(lat, lon, begin_date, end_date)\n",
    "usgs_df = open_usgs_data(site, begin_date, end_date)\n",
    "verde_df = verde_df.reindex(verde_df.index)\n",
    "verde_df['streamflow (ft^3/s)'] = usgs_df['streamflow (ft^3/s)']\n",
    "verde_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How do you get a listing of the columns in `verde_df`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. How do you select the streamflow column in `verde_df`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. How do you plot the streamflow in `verde_df`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. What is the mean streamflow value for the 30 year period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What is the maximum value for the 30 year period?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. How do you find the maximum streamflow value for each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. How do you make a scatter plot of `dayl (s)` versus `tmax (deg c)`?\n",
    "#### INFO: `dayl` is the day length in seconds and `tmax` is the daily maximum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. How do you calculate (and plot) the mean daily minimum temperature for each day of year?  And plot it?\n",
    "#### INFO: Daily minimum temperature is in the column `tmin (deg c)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Building a streamlined workflow\n",
    "\n",
    "For the previous exercises you may have noticed I gave you both the site ID and the lat/lon. Ideally, we should be able to just give you the site ID and get the lat/lon from the USGS site. This will be your task for this exercise. You can retrieve site metadata from the USGS from the following site:\n",
    "\n",
    "https://waterdata.usgs.gov/nwis/inventory?search_criteria=search_site_no&submitted_form=introduction\n",
    "\n",
    "Use this tool to retrieve the tabular data for the Verde river at the site 09506000. You will need to select 3 columns:\n",
    "\n",
    "- Decimal Latitude\n",
    "- Decimal Longitude\n",
    "- Drainage Area (returned in square miles)\n",
    "\n",
    "You will also need to toggle the \"Site-description information displayed in\" radio button and select \"tab-separated format\" from the drop down. Once you have retrieved the table, use it to build a function that lets you put in any site ID and get the lat/lon and drainage area.\n",
    "\n",
    "Then, use this function to get the lat/lon and drainage area for the site 09498500 (SALT RIVER NEAR ROOSEVELT, AZ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usgs_site_info(site_id):\n",
    "    url = f\"\"                                     # TODO: Change this line \n",
    "    response = urllib.request.urlopen(url)\n",
    "    df = pd.read_table(       \n",
    "        response,\n",
    "        comment='#',\n",
    "        skiprows=[25],\n",
    "        sep='\\s+',\n",
    "        engine='python'\n",
    "    )\n",
    "\n",
    "    # Pull out the data\n",
    "    lat = df['dec_lat_va'].item()\n",
    "    lon = df['dec_long_va'].item()\n",
    "    area = df['drain_area_va'].item()\n",
    "\n",
    "    return lat, lon, area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id = '09498500'\n",
    "lat, lon, area = get_usgs_site_info(site_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculating the Runoff ratio\n",
    "\n",
    "From the site info, open the USGS streamflow and Daymet data using the previously defined functions for the period 1990-01-01 to 2020-01-01. Calculate the yearly total (sum) precipitation and streamflow values. From this, calculate the yearly runoff ratio, which is simply the ratio of the total runoff to total precipitation. You will need to convert the streamflow from cubic feet per second to mm of flow. Use the given conversion factors to do these conversions. Finally, make a histogram plot showing the distribution of runoff ratios over the full period.\n",
    "\n",
    "**Note**: The Daymet data is extracted from a single pixel from a 1x1 km grid, but for our purposes assume this is the total over the entire basin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_per_day = 86400\n",
    "m3_per_ft3 = 0.0283\n",
    "m2_per_km2 = 1e6\n",
    "mm_per_m = 1000\n",
    "km2_per_mi2 = 2.59\n",
    "\n",
    "# TODO: Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "has-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
